# -*- coding: utf-8 -*-
"""human traits detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TbriiCepXGz_6gIrZkrzevQylLnWLKFx

#All **Library**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import cv2
import matplotlib.pyplot as plt
# %matplotlib inline
import random
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers,models
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Model
from keras.applications.vgg19 import VGG19,preprocess_input

"""#**RAW data loading**"""

#Mount Drive
from google.colab import drive
drive.mount('/content/drive')

#reading raw data using pandae dataframe
import pandas as pd
traits=pd.read_csv('/content/drive/MyDrive/DIP Project/test/semi final.xlsx - Form Responses 1.csv')
traits.head()

"""#**Data Cleaning**"""

#Drop unnecessary column
traits.drop(['Name','University Name','Department ( বিভাগ)'],axis=1,inplace=True)

#replace Column name 
traits=traits.rename({"Age ":"Age"},axis=1)
traits=traits.rename({"religion":"religious"},axis=1)
traits.head()

"""replace Text with neumeric value"""

traits['introvert']=traits['introvert'].replace("Yes ( হ্যাঁ )",1)\
                                      .replace("No (না)",0)\
                                      .replace("I don't know if I'm an introvert or not. But I cannot talk to strangers easily. But once we get to know each other then we talk a lot.(ইন্ট্রোভার্ট কিনা জানি না।  তবে অপরিচিত কারো সাথে কথা বলতে  পরি না। কিন্তু পরিচয় একবার হয়ে গেলে অনেক বেশি কথা বলি।)",2)
print(traits['introvert'])

traits['hang out']=traits['hang out'].replace("Yes ( হ্যাঁ )",1)\
                                      .replace("No (না)",0)\
                                      .replace("I like to chat but now don't get time.(পছন্দ করি কিন্তু আড্ডা দেওয়া হয় নাহ।)",2)
traits['hang out']

traits['CGPA']=traits['CGPA'].replace("Yes ( হ্যাঁ )",1)\
                                      .replace("No (না)",0)\
                                     
traits['CGPA']

traits['assignments']=traits['assignments'].replace("I start two-three days before submission.(আমি জমা দেওয়ার দুই-তিন দিন আগে শুরু করি।)",0)\
                                      .replace("I start on very first day. (আমি প্রথম দিন থেকেই শুরু করি। )",1)\
                                      .replace("I start toward the end and request sir for extending the time.(শেষের দিকে শুরু করি এবং স্যারকে সময় বাড়িয়ে দেওয়ার জন্য অনুরোধ করি)",2)\
                                      .replace("I start within two or three days.(আমি দুই-তিন দিনের মধ্যে শুরু করি।)",3)\
                                      .replace("I start two-three days before submission.",0)\
                                      .replace("I start toward the end and request sir for extending the time.",0)\
                                     
traits['assignments']

traits['social media']=traits['social media'].replace("0-1 Hour (0-১ ঘন্টা)",0)\
                                      .replace("1-3  Hour (১-৩ ঘন্টা)",1)\
                                      .replace("3-5  Hour (৩-5 ঘন্টা)",2)\
                                      .replace("more than 5 Hour ( ৫ ঘন্টার বেশি)",3)\
                                     
traits['social media']

traits['skills']=traits['skills'].replace("0-1 Hour (0-১ ঘন্টা)",0)\
                                      .replace("1-3  Hour (১-৩ ঘন্টা)",1)\
                                      .replace("3-5  Hour (৩-5 ঘন্টা)",2)\
                                      .replace("more than 5 Hour ( ৫ ঘন্টার বেশি)",3)\
                                     
traits['skills']

traits['study']=traits['study'].replace("0-1 Hour (0-১ ঘন্টা)",0)\
                                      .replace("1-3  Hour (১-৩ ঘন্টা)",1)\
                                      .replace("3-5  Hour (৩-5 ঘন্টা)",2)\
                                      .replace("more than 5 Hour ( ৫ ঘন্টার বেশি)",3)\
                                     
traits['study']

traits['examination']=traits['examination'].replace("Yes ( হ্যাঁ )",1)\
                                      .replace("No (না)",0)\
                                      .replace("No, I know that I would have felt the same thing even I had given  one more day.(না, আমি জানি যে আরও একদিন দিলেও আমি একই জিনিস অনুভব করতাম।)",2)
traits['examination']

traits['hard worker']=traits['hard worker'].replace("Yes ( হ্যাঁ )",1)\
                                      .replace("No (না)",0)
                                     
traits['hard worker']

traits['Age']=traits['Age'].replace("18-22",0)\
                                      .replace("22-26",1)\
                                      .replace("22",1)\
                                      .replace("28",2)\
                                      .replace("32",2)
                                     
traits['Age']

traits.head()

"""#face Segmentation"""

#segmented all image using openCV haarcascade frontalface function
face=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')
for i in range(102):
 
  try:
   img=cv2.imread('/content/drive/MyDrive/pr image3/'+traits["photo"][i])
   img2=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
   f=face.detectMultiScale(img2, 1.3, 5)
  except:
    print("not Done"+traits["photo"][i]) 
  try:
    for(x,y,w,h) in f:
      k=img[y:y+h,x:x+w]
    im_resize=cv2.resize(k,(224,224))
    cv2.imwrite('/content/drive/MyDrive/segmented faces3/'+traits["photo"][i],im_resize)
    print("done  "+traits["photo"][i])
  except:
    print("not Done"+traits["photo"][i])

#those image cannot segmented autometically
  face=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')
  try:
   img=cv2.imread('/content/drive/MyDrive/image/y/inbound5263845978641876546 - Bulbul ahmmed.jpg') #image segmented one by one
   img2=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
   f=face.detectMultiScale(img2, 1.3, 5)
  except:
    print("not Done") 
  try:
    for(x,y,w,h) in f:
      k=img[y:y+h,x:x+w]
    im_resize=cv2.resize(k,(224,224))
    cv2.imwrite('/content/drive/MyDrive/image/yseg/inbound5263845978641876546 - Bulbul ahmmed.jpg',im_resize)
    print("done  ")
    im_resize=0
  except:
    print("not Done")

"""#CGPA column as a label (CNN)"""

Image_Cgpa_train=[]
Image_Cgpa_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["CGPA"][i]
      Image_Cgpa_test.append([image,Class])
    else:
      Class=traits["CGPA"][i]
      Image_Cgpa_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_Cgpa_train)
random.shuffle(Image_Cgpa_test)
X_train=[]
Y_train=[]
X_test=[]
Y_test=[]
for x,y in Image_Cgpa_train:
  X_train.append(x)
  Y_train.append(y)
for x,y in Image_Cgpa_test:
  X_test.append(x)
  Y_test.append(y)

X_train=np.array(X_train).reshape(-1,224,224,3)
X_test=np.array(X_test).reshape(-1,224,224,3)
X_train=X_train/255.0
X_test=X_test/255
Y_train=np.array(Y_train)
Y_test=np.array(Y_test)

CNN=models.Sequential([
    layers.Conv2D(64,(3,3),activation='relu',input_shape=(224,224,3)),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(32,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(16,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
     layers.Conv2D(16,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
     layers.Conv2D(8,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Flatten(),
    layers.Dense(128,activation='relu'),
    layers.Dense(64,activation='relu'),
    layers.Dense(1,activation='sigmoid')


])
CNN.summary()

CNN.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

CNN.fit(X_train,Y_train,epochs=10)

CNN.evaluate(X_test,Y_test)

"""#assignments column as a label (CNN)  

"""

Image_assignments_train=[]
Image_assignments_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["assignments"][i]
      Image_assignments_test.append([image,Class])
    else:
      Class=traits["assignments"][i]
      Image_assignments_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_assignments_train)
random.shuffle(Image_assignments_test)
X_train_assignments=[]
Y_train_assignments=[]
X_test_assignments=[]
Y_test_assignments=[]
for x,y in Image_assignments_train:
  X_train_assignments.append(x)
  Y_train_assignments.append(y)
for x,y in Image_assignments_test:
  X_test_assignments.append(x)
  Y_test_assignments.append(y)

X_train_assignments=np.array(X_train_assignments).reshape(-1,224,224,3)
X_test_assignments=np.array(X_test_assignments).reshape(-1,224,224,3)
X_train_assignments=X_train_assignments/255.0
X_test_assignments=X_test_assignments/255.0
Y_train_assignments=np.array(Y_train_assignments)
Y_test_assignments=np.array(Y_test_assignments)

CNN=models.Sequential([
    layers.Conv2D(32,(3,3),activation='relu',input_shape=(224,224,3)),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(32,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Flatten(),
    layers.Dense(128,activation='relu'),
    layers.Dense(4,activation='softmax')


])
CNN.summary()

CNN.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),optimizer='adam',metrics=['accuracy'])

CNN.fit(X_train_assignments,Y_train_assignments,epochs=10)

CNN.evaluate(X_test_assignments,Y_test_assignments)

"""#introvert  column as a label (CNN)  """

Image_introvert_train=[]
Image_introvert_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0: 
      Class=traits["introvert"][i]
      Image_introvert_test.append([image,Class])
    else:
      Class=traits["introvert"][i]
      Image_introvert_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_introvert_train)
random.shuffle(Image_introvert_test)
X_train_introvert=[]
Y_train_introvert=[]
X_test_introvert=[]
Y_test_introvert=[]
for x,y in Image_introvert_train:
  X_train_introvert.append(x)
  Y_train_introvert.append(y)
for x,y in Image_introvert_test:
  X_test_introvert.append(x)
  Y_test_introvert.append(y)

X_train_introvert=np.array(X_train_introvert).reshape(-1,224,224,3)
X_test_introvert=np.array(X_test_introvert).reshape(-1,224,224,3)
X_train_introvert=X_train_introvert/255.0
X_test_introvert=X_test_introvert/255.0
Y_train_introvert=np.array(Y_train_introvert)
Y_test_introvert=np.array(Y_test_introvert)

CNN=models.Sequential([
    layers.Conv2D(32,(3,3),activation='relu',input_shape=(224,224,3)),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(32,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Flatten(),
    layers.Dense(128,activation='relu'),
    layers.Dense(3,activation='softmax')


])
CNN.summary()

CNN.compile(loss=tf.keras.losses.Poisson(),optimizer='sgd',metrics=['accuracy'])

CNN.fit(X_train_introvert,Y_train_introvert,epochs=10)

CNN.evaluate(X_test_introvert,Y_test_introvert)

"""#Study  column as a label (CNN)  """

Image_study_train=[]
Image_study_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["study"][i]
      Image_study_test.append([image,Class])
    else:
      Class=traits["study"][i]
      Image_study_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_study_train)
random.shuffle(Image_study_test)
X_train_study=[]
Y_train_study=[]
X_test_study=[]
Y_test_study=[]
for x,y in Image_study_train:
  X_train_study.append(x)
  Y_train_study.append(y)
for x,y in Image_study_test:
  X_test_study.append(x)
  Y_test_study.append(y)

X_train_study=np.array(X_train_study).reshape(-1,224,224,3)
X_test_study=np.array(X_test_study).reshape(-1,224,224,3)
X_train_study=X_train_study/255.0
X_test_study=X_test_study/255.0
Y_train_study=np.array(Y_train_study)
Y_test_study=np.array(Y_test_study)

CNN=models.Sequential([
    layers.Conv2D(32,(3,3),activation='relu',input_shape=(224,224,3)),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(32,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Flatten(),
    layers.Dense(128,activation='relu'),
    layers.Dense(4,activation='softmax')


])
CNN.summary()

CNN.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),optimizer='sgd',metrics=['accuracy'])

CNN.fit(X_train_study,Y_train_study,epochs=10)

CNN.evaluate(X_test_study,Y_test_study)

"""#skills column as a label (CNN)"""

Image_skills_train=[]
Image_skills_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["skills"][i]
      Image_skills_test.append([image,Class])
    else:
      Class=traits["skills"][i]
      Image_skills_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_skills_train)
random.shuffle(Image_skills_test)
X_train_skills=[]
Y_train_skills=[]
X_test_skills=[]
Y_test_skills=[]
for x,y in Image_skills_train:
  X_train_skills.append(x)
  Y_train_skills.append(y)
for x,y in Image_skills_test:
  X_test_skills.append(x)
  Y_test_skills.append(y)

X_train_skills=np.array(X_train_skills).reshape(-1,224,224,3)
X_test_skills=np.array(X_test_skills).reshape(-1,224,224,3)
X_train_skills=X_train_skills/255.0
X_test_skills=X_test_skills/255.0
Y_train_skills=np.array(Y_train_skills)
Y_test_skills=np.array(Y_test_skills)

CNN=models.Sequential([
    layers.Conv2D(64,(3,3),activation='relu',input_shape=(224,224,3)),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(32,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(16,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
     layers.Conv2D(16,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
     layers.Conv2D(8,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Flatten(),
    layers.Dense(128,activation='relu'),
    layers.Dense(4,activation='softmax')


])
CNN.summary()
#

CNN.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),optimizer='sgd',metrics=['accuracy'])

CNN.fit(X_train_skills,Y_train_skills,epochs=10)

CNN.evaluate(X_test_skills,Y_test_skills)

"""#puntuality column as a label (CNN)"""

Image_punctuality_train=[]
Image_punctuality_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["punctuality"][i]
      Image_punctuality_test.append([image,Class])
    else:
      Class=traits["punctuality"][i]
      Image_punctuality_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_punctuality_train)
random.shuffle(Image_punctuality_test)
X_train_punctuality=[]
Y_train_punctuality=[]
X_test_punctuality=[]
Y_test_punctuality=[]
for x,y in Image_punctuality_train:
  X_train_punctuality.append(x)
  Y_train_punctuality.append(y)
for x,y in Image_punctuality_test:
  X_test_punctuality.append(x)
  Y_test_punctuality.append(y)

X_train_punctuality=np.array(X_train_punctuality).reshape(-1,224,224,3)
X_test_punctuality=np.array(X_test_punctuality).reshape(-1,224,224,3)
X_train_punctuality=X_train_punctuality/255.0
X_test_punctuality=X_test_punctuality/255.0
Y_train_punctuality=np.array(Y_train_punctuality)
Y_test_punctuality=np.array(Y_test_punctuality)

CNN=models.Sequential([
    layers.Conv2D(64,(3,3),activation='relu',input_shape=(224,224,3)),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(32,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(16,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
     layers.Conv2D(16,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
     layers.Conv2D(8,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Flatten(),
    layers.Dense(128,activation='relu'),
    layers.Dense(10,activation='softmax')


])
CNN.summary()
#

CNN.compile(loss=tf.keras.losses.Poisson(),optimizer='adam',metrics=['accuracy'])

CNN.fit(X_train_punctuality,Y_train_punctuality,epochs=10)

CNN.evaluate(X_test_punctuality,Y_test_punctuality)

"""#comunication skills column as a label (CNN)"""

Image_Cskills_train=[]
Image_Cskills_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["communication skills"][i]
      Image_Cskills_test.append([image,Class])
    else:
      Class=traits["communication skills"][i]
      Image_Cskills_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_Cskills_train)
random.shuffle(Image_Cskills_test)
X_train_Cskills=[]
Y_train_Cskills=[]
X_test_Cskills=[]
Y_test_Cskills=[]
for x,y in Image_Cskills_train:
  X_train_Cskills.append(x)
  Y_train_Cskills.append(y)
for x,y in Image_Cskills_test:
  X_test_Cskills.append(x)
  Y_test_Cskills.append(y)

X_train_Cskills=np.array(X_train_Cskills).reshape(-1,224,224,3)
X_test_Cskills=np.array(X_test_Cskills).reshape(-1,224,224,3)
X_train_Cskills=X_train_Cskills/255.0
X_test_Cskills=X_test_Cskills/255.0
Y_train_Cskills=np.array(Y_train_Cskills)
Y_test_Cskills=np.array(Y_test_Cskills)

CNN=models.Sequential([
    layers.Conv2D(64,(3,3),activation='relu',input_shape=(224,224,3)),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(32,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(16,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
     layers.Conv2D(16,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
     layers.Conv2D(8,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Flatten(),
    layers.Dense(128,activation='relu'),
    layers.Dense(10,activation='softmax')


])
CNN.summary()

CNN.compile(loss=tf.keras.losses.Poisson(),optimizer='adam',metrics=['accuracy'])

CNN.fit(X_train_Cskills,Y_train_Cskills,epochs=10)

CNN.evaluate(X_test_Cskills,Y_test_Cskills)

"""#hangout column as a label (CNN)"""

Image_hang_out_train=[]
Image_hang_out_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["hang out"][i]
      Image_hang_out_test.append([image,Class])
    else:
      Class=traits["hang out"][i]
      Image_hang_out_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_hang_out_train)
random.shuffle(Image_hang_out_test)
X_train_hang_out=[]
Y_train_hang_out=[]
X_test_hang_out=[]
Y_test_hang_out=[]
for x,y in Image_hang_out_train:
  X_train_hang_out.append(x)
  Y_train_hang_out.append(y)
for x,y in Image_hang_out_test:
  X_test_hang_out.append(x)
  Y_test_hang_out.append(y)

X_train_hang_out=np.array(X_train_hang_out).reshape(-1,224,224,3)
X_test_hang_out=np.array(X_test_hang_out).reshape(-1,224,224,3)
X_train_hang_out=X_train_hang_out/255.0
X_test_hang_out=X_test_hang_out/255.0
Y_train_hang_out=np.array(Y_train_hang_out)
Y_test_hang_out=np.array(Y_test_hang_out)

CNN=models.Sequential([
    layers.Conv2D(64,(3,3),activation='relu',input_shape=(224,224,3)),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(32,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(16,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
     layers.Conv2D(16,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
     layers.Conv2D(8,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Flatten(),
    layers.Dense(128,activation='relu'),
    layers.Dense(3,activation='softmax')


])
CNN.summary()

CNN.compile(loss=tf.keras.losses.Poisson(),optimizer='adam',metrics=['accuracy'])

CNN.fit(X_train_hang_out,Y_train_hang_out,epochs=10)

CNN.evaluate(X_test_hang_out,Y_test_hang_out)

"""#hard work column as a label (CNN)"""

Image_hard_worker_train=[]
Image_hard_worker_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["hard worker"][i]
      Image_hard_worker_test.append([image,Class])
    else:
      Class=traits["hard worker"][i]
      Image_hard_worker_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_hard_worker_train)
random.shuffle(Image_hard_worker_test)
X_train_hard_worker=[]
Y_train_hard_worker=[]
X_test_hard_worker=[]
Y_test_hard_worker=[]
for x,y in Image_hard_worker_train:
  X_train_hard_worker.append(x)
  Y_train_hard_worker.append(y)
for x,y in Image_hard_worker_test:
  X_test_hard_worker.append(x)
  Y_test_hard_worker.append(y)

X_train_hard_worker=np.array(X_train_hard_worker).reshape(-1,224,224,3)
X_test_hard_worker=np.array(X_test_hard_worker).reshape(-1,224,224,3)
X_train_hard_worker=X_train_hard_worker/255.0
X_test_hard_worker=X_test_hard_worker/255.0
Y_train_hard_worker=np.array(Y_train_hard_worker)
Y_test_hard_worker=np.array(Y_test_hard_worker)

CNN=models.Sequential([
    layers.Conv2D(64,(3,3),activation='relu',input_shape=(224,224,3)),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(32,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(16,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
     layers.Conv2D(16,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
     layers.Conv2D(8,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Flatten(),
    layers.Dense(64,activation='relu'),
    layers.Dense(32,activation='relu'),
    layers.Dense(1,activation='sigmoid')


])
CNN.summary()

CNN.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

CNN.fit(X_train_hard_worker,Y_train_hard_worker,epochs=10)

CNN.evaluate(X_test_hard_worker,Y_test_hard_worker)

"""#social midia column as a label (CNN)




"""

Image_social_media_train=[]
Image_social_media_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["social media"][i]
      Image_social_media_test.append([image,Class])
    else:
      Class=traits["social media"][i]
      Image_social_media_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_social_media_train)
random.shuffle(Image_social_media_test)
X_train_social_media=[]
Y_train_social_media=[]
X_test_social_media=[]
Y_test_social_media=[]
for x,y in Image_social_media_train:
  X_train_social_media.append(x)
  Y_train_social_media.append(y)
for x,y in Image_social_media_test:
  X_test_social_media.append(x)
  Y_test_social_media.append(y)

X_train_social_media=np.array(X_train_social_media).reshape(-1,224,224,3)
X_test_social_media=np.array(X_test_social_media).reshape(-1,224,224,3)
X_train_social_media=X_train_social_media/255.0
X_test_social_media=X_test_social_media/255.0
Y_train_social_media=np.array(Y_train_social_media)
Y_test_social_media=np.array(Y_test_social_media)

CNN=models.Sequential([
    layers.Conv2D(64,(3,3),activation='relu',input_shape=(224,224,3)),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(32,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(16,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
     layers.Conv2D(16,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
     layers.Conv2D(8,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Flatten(),
    layers.Dense(128,activation='relu'),
    layers.Dense(4,activation='softmax')


])
CNN.summary()

CNN.compile(loss=tf.keras.losses.Poisson(),optimizer='adam',metrics=['accuracy'])

CNN.fit(X_train_social_media,Y_train_social_media,epochs=10)

CNN.evaluate(X_test_social_media,Y_test_social_media)

"""#religious column as a label (CNN)"""

Image_religious_train=[]
Image_religious_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["religious"][i]
      Image_religious_test.append([image,Class])
    else:
      Class=traits["religious"][i]
      Image_religious_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_religious_train)
random.shuffle(Image_religious_test)
X_train_religious=[]
Y_train_religious=[]
X_test_religious=[]
Y_test_religious=[]
for x,y in Image_religious_train:
  X_train_religious.append(x)
  Y_train_religious.append(y)
for x,y in Image_religious_test:
  X_test_religious.append(x)
  Y_test_religious.append(y)

X_train_religious=np.array(X_train_religious).reshape(-1,224,224,3)
X_test_religious=np.array(X_test_religious).reshape(-1,224,224,3)
X_train_religious=X_train_religious/255.0
X_test_religious=X_test_religious/255.0
Y_train_religious=np.array(Y_train_religious)
Y_test_religious=np.array(Y_test_religious)

CNN=models.Sequential([
    layers.Conv2D(64,(3,3),activation='relu',input_shape=(224,224,3)),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(32,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(16,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
     layers.Conv2D(16,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
     layers.Conv2D(8,(3,3),activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Flatten(),
    layers.Dense(128,activation='relu'),
    layers.Dense(10,activation='softmax')


])
CNN.summary()

CNN.compile(loss=tf.keras.losses.Poisson(),optimizer='adam',metrics=['accuracy'])

CNN.fit(X_train_religious,Y_train_religious,epochs=10)

CNN.evaluate(X_test_religious,Y_test_religious)

"""#cgpa column as a label (VGG19)"""

Image_cgpa_train=[]
Image_cgpa_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["CGPA"][i]
      Image_cgpa_test.append([image,Class])
    else:
      Class=traits["CGPA"][i]
      Image_cgpa_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_cgpa_train)
random.shuffle(Image_cgpa_test)
X_train=[]
Y_train=[]
X_test=[]
Y_test=[]
for x,y in Image_cgpa_train:
  X_train.append(x)
  Y_train.append(y)
for x,y in Image_cgpa_test:
  X_test.append(x)
  Y_test.append(y)

X_train=np.array(X_train).reshape(-1,224,224,3)
X_test=np.array(X_test).reshape(-1,224,224,3)
X_train=X_train/255.0
X_test=X_test/255
Y_train=np.array(Y_train)
Y_test=np.array(Y_test)

datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2)

datagen.fit(X_train)

image_size=[224,224]
Vgg=VGG19(input_shape=image_size + [3],weights='imagenet',include_top=False)
for layer in Vgg.layers:
  layer.trainable=False
F=layers.Flatten()(Vgg.output)
prediction=layers.Dense(1,activation='sigmoid')(F)
VGG=Model(inputs=Vgg.input,outputs=prediction)
VGG.summary()

VGG.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

VGG.fit(datagen.flow(X_train, Y_train,
         subset='training'),epochs=10)

VGG.evaluate(X_test,Y_test)

"""#Assignment column as a label (VGG19)"""

Image_assignment_train=[]
Image_assignment_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["assignments"][i]
      Image_assignment_test.append([image,Class])
    else:
      Class=traits["assignments"][i]
      Image_assignment_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_assignment_train)
random.shuffle(Image_assignment_test)
X_train=[]
Y_train=[]
X_test=[]
Y_test=[]
for x,y in Image_assignment_train:
  X_train.append(x)
  Y_train.append(y)
for x,y in Image_assignment_test:
  X_test.append(x)
  Y_test.append(y)

X_train=np.array(X_train).reshape(-1,224,224,3)
X_test=np.array(X_test).reshape(-1,224,224,3)
X_train=X_train/255.0
X_test=X_test/255
Y_train=np.array(Y_train)
Y_test=np.array(Y_test)

datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2)

datagen.fit(X_train)

from keras.applications.vgg19 import VGG19,preprocess_input
image_size=[224,224]
Vgg=VGG19(input_shape=image_size + [3],weights='imagenet',include_top=False)
for layer in Vgg.layers:
  layer.trainable=False
F=layers.Flatten()(Vgg.output)
prediction=layers.Dense(4,activation='softmax')(F)
VGG=Model(inputs=Vgg.input,outputs=prediction)
VGG.summary()

VGG.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),optimizer='adam',metrics=['accuracy'])

VGG.fit(X_train, Y_train,epochs=10)

VGG.evaluate(X_test,Y_test)

"""#introvert column as a label (VGG19)"""

Image_introvert_train=[]
Image_introvert_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["introvert"][i]
      Image_introvert_test.append([image,Class])
    else:
      Class=traits["introvert"][i]
      Image_introvert_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_introvert_train)
random.shuffle(Image_introvert_test)
X_train=[]
Y_train=[]
X_test=[]
Y_test=[]
for x,y in Image_introvert_train:
  X_train.append(x)
  Y_train.append(y)
for x,y in Image_introvert_test:
  X_test.append(x)
  Y_test.append(y)

X_train=np.array(X_train).reshape(-1,224,224,3)
X_test=np.array(X_test).reshape(-1,224,224,3)
X_train=X_train/255.0
X_test=X_test/255
Y_train=np.array(Y_train)
Y_test=np.array(Y_test)

datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2)

datagen.fit(X_train)

from keras.applications.vgg19 import VGG19,preprocess_input
image_size=[224,224]
Vgg=VGG19(input_shape=image_size + [3],weights='imagenet',include_top=False)
for layer in Vgg.layers:
  layer.trainable=False
F=layers.Flatten()(Vgg.output)
prediction=layers.Dense(3,activation='softmax')(F)
VGG=Model(inputs=Vgg.input,outputs=prediction)
VGG.summary()

VGG.compile(loss=tf.keras.losses.Poisson(),optimizer='sgd',metrics=['accuracy'])

VGG.fit(datagen.flow(X_train, Y_train,
         subset='training'),epochs=10)

VGG.evaluate(X_test,Y_test)

"""#study column as a label (VGG19)"""

Image_study_train=[]
Image_study_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["study"][i]
      Image_study_test.append([image,Class])
    else:
      Class=traits["study"][i]
      Image_study_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_study_train)
random.shuffle(Image_study_test)
X_train=[]
Y_train=[]
X_test=[]
Y_test=[]
for x,y in Image_study_train:
  X_train.append(x)
  Y_train.append(y)
for x,y in Image_study_test:
  X_test.append(x)
  Y_test.append(y)

X_train=np.array(X_train).reshape(-1,224,224,3)
X_test=np.array(X_test).reshape(-1,224,224,3)
X_train=X_train/255.0
X_test=X_test/255
Y_train=np.array(Y_train)
Y_test=np.array(Y_test)

datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2)

datagen.fit(X_train)

from keras.applications.vgg19 import VGG19,preprocess_input
image_size=[224,224]
Vgg=VGG19(input_shape=image_size + [3],weights='imagenet',include_top=False)
for layer in Vgg.layers:
  layer.trainable=False
F=layers.Flatten()(Vgg.output)
prediction=layers.Dense(4,activation='softmax')(F)
VGG=Model(inputs=Vgg.input,outputs=prediction)
VGG.summary()

VGG.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),optimizer='adam',metrics=['accuracy'])

VGG.fit(datagen.flow(X_train, Y_train,
         subset='training'),epochs=10)

VGG.evaluate(X_test,Y_test)

"""#skills column as a label (VGG19)"""

Image_skills_train=[]
Image_skills_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["skills"][i]
      Image_skills_test.append([image,Class])
    else:
      Class=traits["skills"][i]
      Image_skills_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_skills_train)
random.shuffle(Image_skills_test)
X_train=[]
Y_train=[]
X_test=[]
Y_test=[]
for x,y in Image_skills_train:
  X_train.append(x)
  Y_train.append(y)
for x,y in Image_skills_test:
  X_test.append(x)
  Y_test.append(y)

X_train=np.array(X_train).reshape(-1,224,224,3)
X_test=np.array(X_test).reshape(-1,224,224,3)
X_train=X_train/255.0
X_test=X_test/255
Y_train=np.array(Y_train)
Y_test=np.array(Y_test)

datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2)

datagen.fit(X_train)

from keras.applications.vgg19 import VGG19,preprocess_input
image_size=[224,224]
Vgg=VGG19(input_shape=image_size + [3],weights='imagenet',include_top=False)
for layer in Vgg.layers:
  layer.trainable=False
F=layers.Flatten()(Vgg.output)
prediction=layers.Dense(4,activation='softmax')(F)
VGG=Model(inputs=Vgg.input,outputs=prediction)
VGG.summary()

VGG.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),optimizer='adam',metrics=['accuracy'])

VGG.fit(X_train, Y_train,epochs=10)

VGG.evaluate(X_test,Y_test)

"""#communication skills column as a label (VGG19)"""

Image_communication_skills_train=[]
Image_communication_skills_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["communication skills"][i]
      Image_communication_skills_test.append([image,Class])
    else:
      Class=traits["communication skills"][i]
      Image_communication_skills_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_communication_skills_train)
random.shuffle(Image_communication_skills_test)
X_train=[]
Y_train=[]
X_test=[]
Y_test=[]
for x,y in Image_communication_skills_train:
  X_train.append(x)
  Y_train.append(y)
for x,y in Image_communication_skills_test:
  X_test.append(x)
  Y_test.append(y)

X_train=np.array(X_train).reshape(-1,224,224,3)
X_test=np.array(X_test).reshape(-1,224,224,3)
X_train=X_train/255.0
X_test=X_test/255
Y_train=np.array(Y_train)
Y_test=np.array(Y_test)

datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2)
datagen.fit(X_train)

from keras.applications.vgg19 import VGG19,preprocess_input
image_size=[224,224]
Vgg=VGG19(input_shape=image_size + [3],weights='imagenet',include_top=False)
for layer in Vgg.layers:
  layer.trainable=False
F=layers.Flatten()(Vgg.output)
prediction=layers.Dense(10,activation='softmax')(F)
VGG=Model(inputs=Vgg.input,outputs=prediction)
VGG.summary()

VGG.compile(loss=tf.keras.losses.Poisson(),optimizer='adam',metrics=['accuracy'])
VGG.fit(X_train, Y_train,epochs=10)

VGG.evaluate(X_test,Y_test)

"""#hang out column as a label (VGG19)"""

Image_hang_out_train=[]
Image_hang_out_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["hang out"][i]
      Image_hang_out_test.append([image,Class])
    else:
      Class=traits["hang out"][i]
      Image_hang_out_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_hang_out_train)
random.shuffle(Image_hang_out_test)
X_train=[]
Y_train=[]
X_test=[]
Y_test=[]
for x,y in Image_hang_out_train:
  X_train.append(x)
  Y_train.append(y)
for x,y in Image_hang_out_test:
  X_test.append(x)
  Y_test.append(y)

X_train=np.array(X_train).reshape(-1,224,224,3)
X_test=np.array(X_test).reshape(-1,224,224,3)
X_train=X_train/255.0
X_test=X_test/255
Y_train=np.array(Y_train)
Y_test=np.array(Y_test)

datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2)
datagen.fit(X_train)

from keras.applications.vgg19 import VGG19,preprocess_input
image_size=[224,224]
Vgg=VGG19(input_shape=image_size + [3],weights='imagenet',include_top=False)
for layer in Vgg.layers:
  layer.trainable=False
F=layers.Flatten()(Vgg.output)
prediction=layers.Dense(3,activation='softmax')(F)
VGG=Model(inputs=Vgg.input,outputs=prediction)
VGG.summary()

VGG.compile(loss=tf.keras.losses.Poisson(),optimizer='adam',metrics=['accuracy'])
VGG.fit(X_train, Y_train,epochs=10)

VGG.evaluate(X_test,Y_test)

"""# punctuality column as a label (VGG19)"""

Image_punctuality_train=[]
Image_punctuality_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["punctuality"][i]
      Image_punctuality_test.append([image,Class])
    else:
      Class=traits["punctuality"][i]
      Image_punctuality_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_punctuality_train)
random.shuffle(Image_punctuality_test)
X_train=[]
Y_train=[]
X_test=[]
Y_test=[]
for x,y in Image_punctuality_train:
  X_train.append(x)
  Y_train.append(y)
for x,y in Image_punctuality_test:
  X_test.append(x)
  Y_test.append(y)

X_train=np.array(X_train).reshape(-1,224,224,3)
X_test=np.array(X_test).reshape(-1,224,224,3)
X_train=X_train/255.0
X_test=X_test/255
Y_train=np.array(Y_train)
Y_test=np.array(Y_test)

datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2)
datagen.fit(X_train)

from keras.applications.vgg19 import VGG19,preprocess_input
image_size=[224,224]
Vgg=VGG19(input_shape=image_size + [3],weights='imagenet',include_top=False)
for layer in Vgg.layers:
  layer.trainable=False
F=layers.Flatten()(Vgg.output)
prediction=layers.Dense(10,activation='softmax')(F)
VGG=Model(inputs=Vgg.input,outputs=prediction)
VGG.summary()

VGG.compile(loss=tf.keras.losses.Poisson(),optimizer='adam',metrics=['accuracy'])
VGG.fit(X_train, Y_train,epochs=10)

VGG.evaluate(X_test,Y_test)

"""#social media column as a label (VGG19)"""

Image_social_media_train=[]
Image_social_media_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["social media"][i]
      Image_social_media_test.append([image,Class])
    else:
      Class=traits["social media"][i]
      Image_social_media_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_social_media_train)
random.shuffle(Image_social_media_test)
X_train=[]
Y_train=[]
X_test=[]
Y_test=[]
for x,y in Image_social_media_train:
  X_train.append(x)
  Y_train.append(y)
for x,y in Image_social_media_test:
  X_test.append(x)
  Y_test.append(y)

X_train=np.array(X_train).reshape(-1,224,224,3)
X_test=np.array(X_test).reshape(-1,224,224,3)
X_train=X_train/255.0
X_test=X_test/255
Y_train=np.array(Y_train)
Y_test=np.array(Y_test)

datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2)
datagen.fit(X_train)

from keras.applications.vgg19 import VGG19,preprocess_input
image_size=[224,224]
Vgg=VGG19(input_shape=image_size + [3],weights='imagenet',include_top=False)
for layer in Vgg.layers:
  layer.trainable=False
F=layers.Flatten()(Vgg.output)
prediction=layers.Dense(4,activation='softmax')(F)
VGG=Model(inputs=Vgg.input,outputs=prediction)
VGG.summary()

VGG.compile(loss=tf.keras.losses.Poisson(),optimizer='adam',metrics=['accuracy'])
VGG.fit(X_train, Y_train,epochs=10)

VGG.evaluate(X_test,Y_test)

"""#hard worker column as a label (VGG19)"""

Image_hard_worker_train=[]
Image_hard_worker_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["hard worker"][i]
      Image_hard_worker_test.append([image,Class])
    else:
      Class=traits["hard worker"][i]
      Image_hard_worker_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_hard_worker_train)
random.shuffle(Image_hard_worker_test)
X_train=[]
Y_train=[]
X_test=[]
Y_test=[]
for x,y in Image_hard_worker_train:
  X_train.append(x)
  Y_train.append(y)
for x,y in Image_hard_worker_test:
  X_test.append(x)
  Y_test.append(y)

X_train=np.array(X_train).reshape(-1,224,224,3)
X_test=np.array(X_test).reshape(-1,224,224,3)
X_train=X_train/255.0
X_test=X_test/255
Y_train=np.array(Y_train)
Y_test=np.array(Y_test)

datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2)
datagen.fit(X_train)

from keras.applications.vgg19 import VGG19,preprocess_input
image_size=[224,224]
Vgg=VGG19(input_shape=image_size + [3],weights='imagenet',include_top=False)
for layer in Vgg.layers:
  layer.trainable=False
F=layers.Flatten()(Vgg.output)
prediction=layers.Dense(1,activation='sigmoid')(F)
VGG=Model(inputs=Vgg.input,outputs=prediction)
VGG.summary()

VGG.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
VGG.fit(datagen.flow(X_train, Y_train,
         subset='training'),epochs=10)

VGG.evaluate(X_test,Y_test)

"""#religious column as a label (VGG19)"""

Image_punctuality_train=[]
Image_punctuality_test=[]

for i in range(102):
   img=traits["photo"][i]
   try:
    image_path='/content/drive/MyDrive/image/final segmented image/'+img
    image_r=cv2.imread(image_path)
    image=cv2.resize(image_r,(224,224))

    if i%5==0:
      Class=traits["punctuality"][i]
      Image_punctuality_test.append([image,Class])
    else:
      Class=traits["punctuality"][i]
      Image_punctuality_train.append([image,Class])
   except:
    print("not done"+str(i))

random.shuffle(Image_punctuality_train)
random.shuffle(Image_punctuality_test)
X_train=[]
Y_train=[]
X_test=[]
Y_test=[]
for x,y in Image_punctuality_train:
  X_train.append(x)
  Y_train.append(y)
for x,y in Image_punctuality_test:
  X_test.append(x)
  Y_test.append(y)

X_train=np.array(X_train).reshape(-1,224,224,3)
X_test=np.array(X_test).reshape(-1,224,224,3)
X_train=X_train/255.0
X_test=X_test/255
Y_train=np.array(Y_train)
Y_test=np.array(Y_test)

datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2)
datagen.fit(X_train)

from keras.applications.vgg19 import VGG19,preprocess_input
image_size=[224,224]
Vgg=VGG19(input_shape=image_size + [3],weights='imagenet',include_top=False)
for layer in Vgg.layers:
  layer.trainable=False
F=layers.Flatten()(Vgg.output)
prediction=layers.Dense(10,activation='softmax')(F)
VGG=Model(inputs=Vgg.input,outputs=prediction)
VGG.summary()

VGG.compile(loss=tf.keras.losses.Poisson(),optimizer='adam',metrics=['accuracy'])
VGG.fit(X_train, Y_train,epochs=10)

VGG.evaluate(X_test,Y_test)

